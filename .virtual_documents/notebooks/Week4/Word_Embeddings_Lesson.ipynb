








# Package imports
import os
import pandas as pd
import numpy as np

import pickle
from gensim.models import Word2Vec
import multiprocessing

import matplotlib.pyplot as plt
from sklearn.manifold import TSNE





# Ensure data files are downloaded
!git lfs pull --include="data/*.pickle"


with open('../../data/aita_comment_trigrams.pickle', 'rb') as f:
    # Load the object from the file
    comments = pickle.load(f)


# Split into lists of words for Word2Vec
comment_list = [comment.split() for comment in comments]
comment_list[0]








cores = multiprocessing.cpu_count() # Number of cores at your disposal

n_features = 300     # Word vector dimensionality (how many features each word will be given)
min_word_count = 10  # Minimum word count to be taken into account
n_workers = cores    # Number of threads to run in parallel (equal to your amount of cores)
window = 5           # Context window size
downsampling = 1e-2  # Downsample setting for frequent words
seed = 1             # Seed for the random number generator (to create reproducible results)
sg = 1               # Skip-gram = 1, CBOW = 0
epochs = 20          # Number of iterations over the corpus

model = Word2Vec(
    sentences=comment_list,
    workers=n_workers,
    vector_size=n_features,
    min_count=min_word_count,
    window=window,
    sample=downsampling,
    seed=seed,
    sg=sg)





model.save('../../data/aita_comments.emb')


model = Word2Vec.load('../../data/aita_comments.emb')





len(model.wv)





model.wv.index_to_key[0]


model.wv.vectors[0]








def get_most_similar_terms(model, token, topn=20):
    """Look up the top N most similar terms to the token."""
    for word, similarity in model.wv.most_similar(positive=[token], topn=topn):
        print(f"{word}: {round(similarity, 3)}")


get_most_similar_terms(model, 'asshole')





get_most_similar_terms(model, 'empathy')


get_most_similar_terms(model, 'relationship')


get_most_similar_terms(model, 'power')


get_most_similar_terms(model, 'man')


get_most_similar_terms(model, 'woman')





words = ['asshole', 'jerk', 'rude', 'inconsiderate',
         'angry', 'upset', 'sad', 'happy', 'frustrated',
         'friend', 'family', 'partner', 'coworker', 'neighbor',
         'apologize', 'forgive', 'ignore', 'confront', 'compromise',
         'right', 'wrong', 'justified', 'unjustified', 'fair', 'unfair',
         'honesty', 'loyalty', 'respect', 'kindness', 'empathy']

# Extract the word vectors
word_vectors = np.array([model.wv[word] for word in words])


# If you get an ImportError in the line tsne=TSNE(), you might need to install scikit-learn:
# %pip install -U scikit-learn 


# Reduce dimensionality using t-SNE
tsne = TSNE(n_components=2, random_state=2, perplexity=2)
reduced_vectors = tsne.fit_transform(word_vectors)


# Store the t-SNE vectors
words_df = pd.DataFrame(reduced_vectors,
                            index=pd.Index([word for word in words]),
                            columns=['x', 'y'])





# You may need to install bokeh if the following cell does not run
#%conda install bokeh


import bokeh
from bokeh.plotting import figure, show, output_notebook
from bokeh.models import HoverTool, ColumnDataSource, LabelSet

output_notebook()
bokeh.io.output_notebook()


# Add our DataFrame as a ColumnDataSource for Bokeh
plot_data = ColumnDataSource(words_df)
# Create the plot and configure the title, dimensions, and tools
tsne_plot = figure(title='t-SNE Word Embeddings')
# Add a hover tool to display words on roll-over
tsne_plot.add_tools(HoverTool(tooltips='@index'))
# Use scatter() instead of circle() - updated syntax
tsne_plot.scatter('x', 'y',
                  source=plot_data,
                  color='blue',
                  size=10,
                  hover_line_color='black')
# Add labels to the points
labels = LabelSet(x='x', y='y', text='index', level='glyph',
                  x_offset=5, y_offset=5, source=plot_data)
tsne_plot.add_layout(labels)
# Engage!
show(tsne_plot)





tsne = TSNE(init='pca', learning_rate='auto')
X_tsne = tsne.fit_transform(model.wv.vectors)





# Store the t-SNE vectors
tsne_df = pd.DataFrame(X_tsne,
                       index=pd.Index(model.wv.index_to_key),
                       columns=['x', 'y'])


# Create some filepaths to save our model
tsne_path = '../../data/tsne_model'
tsne_df_path = '../../data/tsne_df.pkl'


# Save to disk
with open(tsne_path, 'wb') as f:
    pickle.dump(X_tsne, f)

tsne_df.to_pickle(tsne_df_path)





with open(tsne_path, 'rb') as f:
    X_tsne = pickle.load(f)
    
tsne_df = pd.read_pickle(tsne_df_path)


# Add our DataFrame as a ColumnDataSource for Bokeh
plot_data = ColumnDataSource(tsne_df)

# Create the plot and configure the title, dimensions, and tools
tsne_plot = figure(title='t-SNE Word Embeddings')

# Add a hover tool to display words on roll-over
tsne_plot.add_tools(HoverTool(tooltips='@index') )

# Draw the words as circles on the plot
tsne_plot.circle('x', 'y',
                 source=plot_data,
                 color='blue',
                 line_alpha=0.2,
                 fill_alpha=0.1,
                 size=10,
                 hover_line_color='black')

# Engage!
show(tsne_plot)








# Import function to calculate biased words
from utils import calculate_biased_words
import nltk
nltk.download('averaged_perceptron_tagger_eng')






target1 = ['sister' , 'female' , 'woman' , 'girl' , 'daughter' , 'she' , 'hers' , 'her']
target2 = ['brother' , 'male' , 'man' , 'boy' , 'son' , 'he' , 'his' , 'him'] 


model = Word2Vec.load('../../data/aita_comments.emb')


[b1, b2] = calculate_biased_words(model, target1, target2, 4)





print('Biased words towards target set 1')
print([word for word in b1.keys()])


print('Biased words towards target set 2')
print([word for word in b2.keys()] )





import matplotlib.pyplot as plt
import numpy as np

from sklearn.manifold import TSNE
%matplotlib inline


with open(tsne_path, 'rb') as f:
    X_tsne = pickle.load(f)
    
tsne_df = pd.read_pickle(tsne_df_path)


# Convert biased term keys to arrays
target1_idx = np.array([model.wv.key_to_index[key] for key in b1.keys()])
target2_idx = np.array([model.wv.key_to_index[key] for key in b2.keys()])


# Find t-sne values for the biased sets
X_target1 = X_tsne[target1_idx]
X_target2 = X_tsne[target2_idx]


from bokeh.io import show, output_notebook, output_file
from bokeh.plotting import figure
from bokeh.models import ColumnDataSource, LabelSet

# Set up the Bokeh plot
output_notebook()

p = figure()

# Create ColumnDataSource for X_target1 (blue)
source1 = ColumnDataSource(data=dict(x=X_target1[:, 0], y=X_target1[:, 1], label=[model.wv.index_to_key[idx] for idx in target1_idx]))

# Create ColumnDataSource for X_target2 (red)
source2 = ColumnDataSource(data=dict(x=X_target2[:, 0], y=X_target2[:, 1], label=[model.wv.index_to_key[idx] for idx in target2_idx]))

# Add scatter plot for X_target1 (blue)
p.scatter(x='x', y='y', color='blue', size=8, source=source1)

# Add scatter plot for X_target2 (red)
p.scatter(x='x', y='y', color='red', size=8, source=source2)

# Add labels for X_target1
labels1 = LabelSet(x='x', y='y', text='label', x_offset=6, y_offset=3, source=source1)
p.add_layout(labels1)

# Add labels for X_target2
labels2 = LabelSet(x='x', y='y', text='label', x_offset=6, y_offset=3, source=source2)
p.add_layout(labels2)

# Show the plot
show(p)









