








import pandas as pd

# Load your preprocessed AITA CSV (change the filename if needed)
df = pd.read_csv('../../data/aita_pp.csv')


docs = df['pp_text'].tolist()





topic_model = BERTopic(verbose=True)
topics, probabilities = topic_model.fit_transform(docs)





topic_info = topic_model.get_topic_info()
topic_info.head(10)





# How many topics do we have?
topic_info.shape





# Show top words for topic 0
topic_model.get_topic(0)





fig = topic_model.visualize_topics()
fig.show()





# Reduce the number of topics (set to the number you want)
target_num_topics = 30  # change this as needed
topic_model.reduce_topics(docs, nr_topics=target_num_topics)

# Re-visualize the intertopic distance map
fig = topic_model.visualize_topics()
fig.show()








import matplotlib.pyplot as plt

freq_df = topic_model.get_topic_info()
freq_df = freq_df[freq_df.Topic != -1]   # remove outlier topic -1
freq_df = freq_df.sort_values('Count', ascending=False)
top_n = 10
freq_top_n = freq_df.head(top_n)
print(freq_top_n[['Topic', 'Count', 'Name']])

plt.figure(figsize=(8,5))
plt.bar(range(len(freq_top_n)), freq_top_n['Count'], color='skyblue')
plt.xticks(range(len(freq_top_n)), [str(t) for t in freq_top_n['Topic']], rotation=45)
plt.title(f'Top {top_n} Topic Frequencies')
plt.xlabel('Topic')
plt.ylabel('Number of Posts')
plt.show()





for topic_num in topic_model.get_topic_info().Topic:
    if topic_num == -1:
        continue  # skip the outlier topic if you want
    top_words = [word for word, _ in topic_model.get_topic(topic_num)]
    print(f"Topic {topic_num}: {', '.join(top_words)}")





#  View example posts for a specific topic (change the topic number)
topic_num = 0  # pick any topic number you see in topic_info
examples = topic_model.get_representative_docs(topic_num)
for i, doc in enumerate(examples[:3]):  # show up to 3 examples
    print(f"Example {i+1} for topic {topic_num}:\n", doc, "\n")



